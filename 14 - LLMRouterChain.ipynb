{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5284ede",
   "metadata": {},
   "source": [
    "# LLMRouterChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3fd50f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os \n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "from langchain.chains import LLMChain,SequentialChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da30bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc1fc9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc020f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15220cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_template=\"\"\"You are a very smart human resources person. \\\n",
    "You are great at answering questions about human resources in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f421da",
   "metadata": {},
   "outputs": [],
   "source": [
    "law_template=\"\"\"You are a very smart lawyer. \\\n",
    "You are great at answering questions about the law in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca50521",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "{\n",
    "    'name':'human resources',\n",
    "    'description':'Answer human resources questions',\n",
    "    'template':hr_template},\n",
    "\n",
    "{\n",
    "    'name':'law',\n",
    "    'description':'Answers legal questions',\n",
    "    'template':law_template}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9131fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d4bec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_info in prompt_infos:\n",
    "    name = p_info['name']\n",
    "    prompt_template = p_info['template']\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm,prompt=prompt)\n",
    "    destination_chains[name] = chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7b7fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template('{input}')\n",
    "\n",
    "default_chain = LLMChain(llm=llm,prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae2dc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "{destinations}\n",
      "\n",
      "<< INPUT >>\n",
      "{{input}}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(MULTI_PROMPT_ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d266aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "destinations=[\n",
    "f\"{p['name']}: {p['description']}\" for p in prompt_infos\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b12999c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['human resources: Answer human resources questions',\n",
       " 'law: Answers legal questions']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfe483ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human resources: Answer human resources questions\n",
      "law: Answers legal questions\n"
     ]
    }
   ],
   "source": [
    "destination_str = \"\\n\".join(destinations)\n",
    "\n",
    "print(destination_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a597cda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\\n\\n<< FORMATTING >>\\nReturn a markdown code snippet with a JSON object formatted to look like:\\n```json\\n{{\\n    \"destination\": string \\\\ name of the prompt to use or \"DEFAULT\"\\n    \"next_inputs\": string \\\\ a potentially modified version of the original input\\n}}\\n```\\n\\nREMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\\nREMEMBER: \"next_inputs\" can just be the original input if you don\\'t think any modifications are needed.\\n\\n<< CANDIDATE PROMPTS >>\\nhuman resources: Answer human resources questions\\nlaw: Answers legal questions\\n\\n<< INPUT >>\\n{input}\\n\\n<< OUTPUT (must include ```json at the start of the response) >>\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destination_str)\n",
    "\n",
    "router_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7c75f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "law: {'input': 'How do intellectual property laws address the use of AI-generated content?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Thank you for your kind words. Intellectual property laws are still evolving to address the use of AI-generated content. Generally, the creator of the AI-generated content would own the copyright to it. However, if the AI-generated content is created by an AI without human involvement, the question of ownership becomes more complex. Some jurisdictions may consider the AI itself as the author, while others might attribute the creation to the person or organization that owns or operates the AI. To navigate this issue, countries may need to adapt their laws and establish clear guidelines regarding ownership and rights in AI-generated content. It's important to consult with legal professionals who specialize in intellectual property law to get the most accurate and up-to-date advice.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_prompt = PromptTemplate(template=router_template,\n",
    "input_variables=['input'],\n",
    "output_parser=RouterOutputParser())\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm,router_prompt)\n",
    "\n",
    "chain = MultiPromptChain(router_chain=router_chain,\n",
    "destination_chains=destination_chains,\n",
    "default_chain=default_chain,verbose=True)\n",
    "\n",
    "chain.run(\"How do intellectual property laws address the use of AI-generated content?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d26c254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "human resources: {'input': 'How do you handle conflict between team members?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Handling conflict between team members is a crucial part of being an effective human resources professional. Here are some steps you can take to address conflicts:\\n\\n1. Encourage open communication: Encourage the team members involved to communicate directly with each other, emphasizing active listening and respectful dialogue.\\n\\n2. Create a safe space for discussion: Provide a neutral and confidential environment where team members can express their concerns and feelings without fear of judgment or retaliation.\\n\\n3. Act as a mediator: If necessary, step in as a neutral third party to facilitate a discussion between the conflicting parties, helping them understand each other's perspectives.\\n\\n4. Identify the root cause: Explore the underlying reasons for the conflict, as it could be due to differences in work styles, miscommunication, or conflicting goals. Understanding the root cause helps in finding effective resolutions.\\n\\n5. Encourage empathy and understanding: Promote empathy among team members by encouraging them to see the situation from the other person's point of view. This can help foster understanding and reduce hostility.\\n\\n6. Seek a mutually beneficial solution: Work together with the conflicting parties to find a resolution that is satisfactory to both sides. Encourage compromise and collaboration to reach a mutually beneficial outcome.\\n\\n7. Provide ongoing support: Once a resolution is reached, follow up with the team members involved to ensure that the conflict has been fully resolved. Offer support and guidance if necessary.\\n\\nRemember, each conflict situation is unique, so adapt these steps to fit the specific circumstances. If you're unsure about the best course of action, don't hesitate to seek guidance from more experienced colleagues or HR resources.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"How do you handle conflict between team members?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d79918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b79ce20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
