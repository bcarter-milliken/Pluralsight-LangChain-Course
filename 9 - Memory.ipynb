{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472a7aec",
   "metadata": {},
   "source": [
    "# Memory Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de456a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os \n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3592ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb4be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ba6dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2e55e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93a76b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f5aa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Tom.  How are you today?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Tom! I'm an AI, so I don't have feelings, but I'm here to help you. How can I assist you today?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Hi, my name is Tom.  How are you today?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3162a977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Tom.  How are you today?\n",
      "AI: Hello Tom! I'm an AI, so I don't have feelings, but I'm here to help you. How can I assist you today?\n",
      "Human: So what is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Tom.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='So what is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e30b5c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: Hi, my name is Tom.  How are you today?\\nAI: Hello Tom! I'm an AI, so I don't have feelings, but I'm here to help you. How can I assist you today?\\nHuman: So what is my name?\\nAI: Your name is Tom.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28b1244a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is Tom.  How are you today?\\nAI: Hello Tom! I'm an AI, so I don't have feelings, but I'm here to help you. How can I assist you today?\\nHuman: So what is my name?\\nAI: Your name is Tom.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76054619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Tom.  How are you today?\n",
      "AI: Hello Tom! I'm an AI, so I don't have feelings, but I'm here to help you. How can I assist you today?\n",
      "Human: So what is my name?\n",
      "AI: Your name is Tom.\n",
      "Human: Tell me something funny.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Why don't scientists trust atoms? Because they make up everything!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Tell me something funny.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daefe713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: Hi, my name is Tom.  How are you today?\\nAI: Hello Tom! I'm an AI, so I don't have feelings, but I'm here to help you. How can I assist you today?\\nHuman: So what is my name?\\nAI: Your name is Tom.\\nHuman: Tell me something funny.\\nAI: Why don't scientists trust atoms? Because they make up everything!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "080ab254",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({'input':'What type of typing system does Python employ: static or dynamic?'}, {'output': 'Dynamic'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bb64b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: Hi, my name is Tom.  How are you today?\\nAI: Hello Tom! I'm an AI, so I don't have feelings, but I'm here to help you. How can I assist you today?\\nHuman: So what is my name?\\nAI: Your name is Tom.\\nHuman: Tell me something funny.\\nAI: Why don't scientists trust atoms? Because they make up everything!\\nHuman: What type of typing system does Python employ: static or dynamic?\\nAI: Dynamic\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70476fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "memory = ConversationBufferWindowMemory(k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55911ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=false\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d7d54ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"Hi, I recently purchased a product from your website, but I haven't received a confirmation email yet. Can you help?\"}, {\"output\": \"Hello, I'm sorry to hear that. Let me check the details for you. Can you provide your order number?\"})\n",
    "memory.save_context({\"input\": \"Sure, it's #12345.\"}, {\"output\": \"Thank you. I see your order. It seems there was a minor glitch. I've sent the confirmation email again. Please check.\"})\n",
    "memory.save_context({\"input\": \"Got it! Thanks for the quick resolution.\"}, {\"output\": \"You're welcome, Ivy! If you have any other concerns, feel free to ask. Have a great day!.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29319b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: Sure, it's #12345.\\nAI: Thank you. I see your order. It seems there was a minor glitch. I've sent the confirmation email again. Please check.\\nHuman: Got it! Thanks for the quick resolution.\\nAI: You're welcome, Ivy! If you have any other concerns, feel free to ask. Have a great day!.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbd0927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "015d6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fbd706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39fbd7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The best color is subjective and can vary from person to person. Some people may find blue to be the best color because it is calming and represents loyalty. Others may prefer green because it symbolizes nature and growth. It really depends on personal preference and the context in which the color is being used. What is your favorite color?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='what is he best color.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "940de096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: what is he best color.\\nAI: The best color is subjective and can vary from person to person. Some people may find blue to be the best color because it is calming and represents loyalty. Others may prefer green because it symbolizes nature and growth. It really depends on personal preference and the context in which the color is being used. What is your favorite color?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94b4f265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python is a high-level programming language that was created by Guido van Rossum and first released in 1991. It is known for its simplicity and readability, making it a popular choice for beginners and experienced programmers alike. Python is widely used in various domains such as web development, data analysis, artificial intelligence, and scientific computing. It has a large and active community of developers who contribute to its libraries and frameworks, making it even more powerful and versatile. Python uses a syntax that emphasizes code readability and uses indentation rather than brackets or symbols to define code blocks. Overall, Python is a versatile language that is used in a wide range of applications and is known for its ease of use and flexibility.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='What is the Python language?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b976885d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "025ffc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "847967ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9b9b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fb4f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hey, my name is Tom.\"}, {\"output\": \"Nice to meet you, Tom.  How are things with you?\"})\n",
    "memory.save_context({\"input\": \"I'm doing great! And you?\"}, {\"output\": \"The same!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9d1b2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The human introduces themselves as Tom. The AI greets Tom and asks how things are with him.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.moving_summary_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6a98e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
