{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3191092",
   "metadata": {},
   "source": [
    "# PromptTemplate - No Input Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e51a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d717b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom_functions as cf\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Set API Key in environment\n",
    "# Then delete from string\n",
    "# Using BCarter-OpenAI > Get medel from Studio Deployment\n",
    "os.environ['AZURE_OPENAI_API_KEY'] = cf.azure_openai_api_key()\n",
    "os.environ['AZURE_OPENAI_ENDPOINT'] = cf.azure_openai_endpoint()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65a5dd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Answer from OpenAI: The topic \"Why are cats so fluffy?\" explores the reasons behind the fluffiness of cats and seeks to understand the evolutionary, physiological, and functional aspects related to their fur. It delves into the characteristics of cats' fur, including its density, texture, and length, and examines the multiple purposes it serves for feline species. The discourse also investigates the role of genetic factors in determining a cat's fluffiness, examining how certain breeds possess more abundant and luxurious coats. Additionally, the topic may touch upon the benefits and adaptive advantages of fluffy fur, such as insulation, protection, camouflage, sensory enhancement, and communication. Various theories and scientific explanations are likely to be discussed, shedding light on the specific mechanisms that contribute to cats' fluffiness, such as specific hair types, follicular structure, or specific genetic mutations. By understanding why cats have such fluffy coats, we gain insights into the unique characteristics of these beloved pets and their interactions with their environment.\n"
     ]
    }
   ],
   "source": [
    "def describe(subject):\n",
    "    prompt = f\"Describe this topic: {subject}\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    reply = client.chat.completions.create(\n",
    "        model=\"GPT-35-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    return reply.choices[0].message.content\n",
    "\n",
    "question = input(\"Please enter a prompt: \")\n",
    "openai_reply = describe(question)\n",
    "print(\"------------\")\n",
    "print(f\"Answer from OpenAI: {openai_reply}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfdf4e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(input_variables=[],template='What is chemistry?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fb22cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=[], template='What is chemistry?')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "188b94dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is chemistry?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03734e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAI(openai_api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client(template.format()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d284e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_template(subject):\n",
    "    \n",
    "    prompt = PromptTemplate(input_variables=[\"subject\"],\n",
    "    template=\"What is {subject}?\")\n",
    "\n",
    "    return llm(prompt.format(subject=subject))\n",
    "\n",
    "question = input(\"Please enter a prompt: \")\n",
    "openai_reply = describe_template(question)\n",
    "print(\"------------\")\n",
    "print(f\"Answer from OpenAI: {openai_reply}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_template_two(subject, tone):\n",
    "    \n",
    "    prompt = PromptTemplate(input_variables=[\"subject\", \"tone\"],\n",
    "    template=\"What is {subject}? The tone should be {tone}.\")\n",
    "\n",
    "    return llm(prompt.format(subject=subject, tone=tone))\n",
    "\n",
    "question = input(\"Please enter a prompt: \")\n",
    "tone = input(\"Please enter the tone: \")\n",
    "openai_reply = describe_template_two(question, tone)\n",
    "print(\"------------\")\n",
    "print(f\"Answer from OpenAI: {openai_reply}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9b5de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate,SystemMessagePromptTemplate,AIMessagePromptTemplate,HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0611f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage,HumanMessage,SystemMessage\n",
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96df49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chat_llm = ChatOpenAI(openai_api_key=openai.api_key,model_name=\"gpt-3.5-turbo\")\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = \"2024-02-01\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    model_name = \"GPT-35-turbo\",\n",
    "    max_tokens = 100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3634d296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Answer from OpenAI: Photosynthesis is the process by which plants, algae, and some bacteria convert sunlight, carbon dioxide, and water into glucose (a sugar) and oxygen. It is a vital process that allows plants to produce food and oxygen, making it essential for the survival of life on Earth. \n",
      "\n",
      "During photosynthesis, plants use pigments called chlorophyll, located in specialized structures called chloroplasts, to capture sunlight energy. This energy is used to convert carbon dioxide and water into glucose, a form of\n"
     ]
    }
   ],
   "source": [
    "def consult(expertise, question):\n",
    "    \n",
    "    system_template = 'You are a consultant that is an expert in {expertise}'\n",
    "    system_message = SystemMessagePromptTemplate.from_template(system_template)\n",
    "    \n",
    "    human_template = \"{question}\"\n",
    "    human_message = HumanMessagePromptTemplate.from_template(human_template)\n",
    "    \n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message,human_message])\n",
    "    prompt = chat_prompt.format_prompt(expertise=expertise,question=question).to_messages()\n",
    "    reply = llm.invoke(prompt)\n",
    "\n",
    "    return reply.content\n",
    "    \n",
    "    #return reply.content\n",
    "\n",
    "expertise = input(\"What is the expertise of the consultant? \")\n",
    "question = input(\"What is the question for the consultant? \")\n",
    "openai_reply = consult(expertise, question)\n",
    "print(\"------------\")\n",
    "print(f\"Answer from OpenAI: {openai_reply}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22fda051",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = 'You are a consultant that is an expert in {expertise}'\n",
    "system_message = SystemMessagePromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e344adfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['expertise']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62f1a73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Answer from OpenAI: Verily, I didst partake in devouring all of yon sustenance yesternight.\n"
     ]
    }
   ],
   "source": [
    "def shakespeare_convert(modern_text_input):\n",
    "    template = \"You are an expert in translating modern Enlish into Shakespearean prose.\"\n",
    "    system_message = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "    modern_text = \"I just updated my profile picture.\"\n",
    "    modern_text_one = HumanMessagePromptTemplate.from_template(modern_text)\n",
    "\n",
    "    shakespeare_text = \"I hath but refreshed mine own visage upon yon profile.\"\n",
    "    shakespeare_text_one = AIMessagePromptTemplate.from_template(shakespeare_text)\n",
    "    \n",
    "    modern_text = \"I binge-watched that series last night.\"\n",
    "    modern_text_two = HumanMessagePromptTemplate.from_template(modern_text)\n",
    "\n",
    "    shakespeare_text = \"I didst indulge in viewing yon series through the night.\"\n",
    "    shakespeare_text_two = AIMessagePromptTemplate.from_template(shakespeare_text)    \n",
    "\n",
    "    human_template = \"{modern_text_input}\"\n",
    "    human_message = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [system_message, modern_text_one, shakespeare_text_one, modern_text_two, shakespeare_text_two, human_message]\n",
    "    )\n",
    "\n",
    "    prompt = chat_prompt.format_prompt(modern_text_input=modern_text_input).to_messages()\n",
    "\n",
    "    reply = llm.invoke(prompt)\n",
    "\n",
    "    return reply.content\n",
    "\n",
    "modern_text_input = input(\"Enter a sentence: \")\n",
    "openai_reply = shakespeare_convert(modern_text_input)\n",
    "print(\"------------\")\n",
    "print(f\"Answer from OpenAI: {openai_reply}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aa3bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
